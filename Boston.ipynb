{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e8dfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb761402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "load_boston = load_boston()\n",
    "X = load_boston.data\n",
    "y = load_boston.target\n",
    "data = pd.DataFrame(X, columns=load_boston.feature_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da215d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y values to categorical values\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y = lab.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff902897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87223231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "      results = cross_validate(estimator=model,\n",
    "                                X=_X,\n",
    "                                y=_y,\n",
    "                                cv=_cv,\n",
    "                                scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      results \n",
    "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22804ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped Bar Chart for both training and validation data\n",
    "def plot_result(x_label, y_label, plot_title, train_data, val_data):\n",
    "        '''Function to plot a grouped bar chart showing the training and validation\n",
    "          results of the ML model in each fold after applying K-fold cross-validation.\n",
    "         Parameters\n",
    "         ----------\n",
    "         x_label: str, \n",
    "            Name of the algorithm used for training e.g 'Decision Tree'\n",
    "          \n",
    "         y_label: str, \n",
    "            Name of metric being visualized e.g 'Accuracy'\n",
    "         plot_title: str, \n",
    "            This is the title of the plot e.g 'Accuracy Plot'\n",
    "         \n",
    "         train_result: list, array\n",
    "            This is the list containing either training precision, accuracy, or f1 score.\n",
    "        \n",
    "         val_result: list, array\n",
    "            This is the list containing either validation precision, accuracy, or f1 score.\n",
    "         Returns\n",
    "         -------\n",
    "         The function returns a Grouped Barchart showing the training and validation result\n",
    "         in each fold.\n",
    "        '''\n",
    "        \n",
    "        # Set size of plot\n",
    "        plt.figure(figsize=(12,6))\n",
    "        labels = [\"1st Fold\", \"2nd Fold\", \"3rd Fold\", \"4th Fold\", \"5th Fold\"]\n",
    "        X_axis = np.arange(len(labels))\n",
    "        ax = plt.gca()\n",
    "        plt.ylim(0.40000, 1)\n",
    "        plt.bar(X_axis-0.2, train_data, 0.4, color='blue', label='Training')\n",
    "        plt.bar(X_axis+0.2, val_data, 0.4, color='red', label='Validation')\n",
    "        plt.title(plot_title, fontsize=30)\n",
    "        plt.xticks(X_axis, labels)\n",
    "        plt.xlabel(x_label, fontsize=14)\n",
    "        plt.ylabel(y_label, fontsize=14)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "587b046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual value: 209\n",
      "Predicted value: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"C:\\Users\\Adham\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1294, in _check_set_wise_labels\n",
      "    raise ValueError(\"Target is %s but average='binary'. Please \"\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression();\n",
    "model_name=\"Logistic Regression\"\n",
    "model.fit(X_train,Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Actual value: {}\".format(Y_test[0]))\n",
    "print(\"Predicted value: {}\".format(predictions[0]))\n",
    "final_result = cross_validation(model,X,y,5)\n",
    "#print(final_result)\n",
    "#print(\"Test set RMSE:\", mean_squared_error(Y_test, model.predict(X_test), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2bc3816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x289ccc9a9a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59adf2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
